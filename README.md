# ğŸš€ High-Throughput Fan-Out Engine

A production-ready, scalable, and high-performance **fan-out data processing engine** built using Java 21. This project demonstrates modern backend design principles including concurrency, reliability, fault tolerance, extensibility, and observability.

**Purpose**: Efficiently read records from various file formats and distribute them to multiple downstream systems (REST APIs, gRPC services, Message Queues, Databases) with configurable rate limiting, automatic retries, and zero data loss guarantee.

---

## âœ¨ Key Features

### ğŸ¯ Core Features
- **High Throughput**: Parallel processing using Java 21 Virtual Threads
- **Zero Data Loss**: Dead Letter Queue (DLQ) persistence for failed records
- **Backpressure Handling**: BlockingQueue prevents memory overflow
- **Configuration-Driven**: External `application.yaml` for all settings
- **Multi-Format Support**: JSON, JSONL, CSV, Fixed-width file formats
- **Data Transformation**: Strategy pattern with 4 format converters
- **Fault Tolerance**: Automatic retry (max 3 attempts) with exponential backoff
- **Rate Limiting**: Per-sink configurable rate limiting via semaphore
- **Observability**: Real-time metrics every 5 seconds
- **Extensible Design**: Add new sinks without modifying core logic

### ğŸ”§ Technical Highlights
- âœ… **Virtual Threads**: Handles millions of concurrent tasks efficiently
- âœ… **Design Patterns**: Strategy, Factory, Template Method, Observer
- âœ… **Memory Efficient**: Streaming architecture (no full file load)
- âœ… **Mockito Tests**: Comprehensive unit tests with mocks
- âœ… **Thread-Safe**: ConcurrentHashMap, AtomicLong, BlockingQueue
- âœ… **Production-Ready**: Error handling, logging, metrics

---

## ğŸ—ï¸ Architecture

### System Layers

```
Ingestion (FileProducer)
          â†“
      BlockingQueue (Backpressure)
          â†“
    FanOutOrchestrator
          â†“
        â”Œâ”€â”´â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
        â†“   â†“     â†“    â†“
   Transform Layer (4 Transformers)
        â†“   â†“     â†“    â†“
    Sink Layer (4 Sinks with Rate Limiting)
        â†“   â†“     â†“    â†“
   Retry & DLQ (Max 3 retries, then DLQ)
        â†“   â†“     â†“    â†“
  Metrics & Observability (Every 5 seconds)
```

### Supported Sinks
1. **REST Sink** (50 req/sec) - HTTP/2 POST requests
2. **gRPC Sink** (200 req/sec) - Bidirectional streaming gRPC
3. **Message Queue Sink** (500 req/sec) - Kafka/RabbitMQ simulation
4. **Wide-Column DB Sink** (1000 req/sec) - Cassandra/Aerospike/DynamoDB

### Input Formats Supported
- **JSON**: `[{"id":1}, {"id":2}]`
- **JSONL**: One JSON object per line
- **CSV**: Headers + comma-separated values
- **Fixed-width**: Tab or pipe-delimited columns

### Data Transformations
- **JSON** â†’ REST (validation only)
- **JSON** â†’ **XML** (with CDATA wrapping)
- **JSON** â†’ **Protobuf** (binary encoding simulation)
- **JSON** â†’ **Avro** (binary encoding simulation)

---

## ğŸ“‹ Configuration

### application.yaml

```yaml
# Input file configuration
input:
  filePath: "sample-data/input.json"
  format: "jsonl"  # json, jsonl, csv, fixedwidth

# Queue configuration (backpressure)
queue:
  capacity: 1000
  timeoutMs: 5000

# Sink-specific rate limits
sinks:
  rest:
    rateLimit: 50
    endpoint: "http://api.example.com"
  grpc:
    rateLimit: 200
    endpoint: "grpc://api.example.com:50051"
  mq:
    rateLimit: 500
    endpoint: "kafka://localhost:9092"
  db:
    rateLimit: 1000
    endpoint: "cassandra://localhost:9042"

# Dead Letter Queue (Zero data loss)
dlq:
  enabled: true
  filePath: "dlq/failed-records.jsonl"
  maxRetries: 3

# Metrics reporting
metrics:
  enabled: true
  intervalSeconds: 5
  verboseLogging: true

# Performance tuning
performance:
  virtualThreads: true
  batchSize: 100
  memoryHeapMb: 512
```

---
## ğŸš€ Getting Started

### Prerequisites
- Java 21 or later (check with `java -version`)
- Maven 3.8+ (check with `mvn -version`)
- Git (optional, for cloning repository)

### Quick Start (5 minutes)

```bash
# 1ï¸âƒ£ Clone the repository (or download/extract the ZIP)
git clone https://github.com/yourusername/High-Throughput-Fan-Out-Engine.git
cd High-Throughput-Fan-Out-Engine

# 2ï¸âƒ£ Build the project
mvn clean install

# 3ï¸âƒ£ Run tests (verify everything works)
mvn test

# 4ï¸âƒ£ Run in test mode
java -jar target/fanout-engine.jar --testMode
```

**Expected Output:**
```
ğŸš€ Starting High Throughput Fan-Out Engine...
ğŸ“Š Config: Queue=1000, Sinks=4, DLQ=true
ğŸ§ª Test Mode: Processing 3 records
âœ… Processing complete
ğŸ“ˆ === FINAL METRICS ===
   Processed: 3
   Throughput: 600 records/sec
   Success: {REST=3, GRPC=3, MQ=3, DB=3}
   Failed: {}
   DLQ Records: 0
=======================
```

### Build Options

```bash
# Build and run all tests
mvn clean install

# Build without running tests (faster)
mvn clean package -DskipTests

# Run specific test
mvn test -Dtest=TransformerTest

# Run with verbose output for debugging
mvn clean test -X
```

### Run Options

```bash
# ğŸ¯ Test mode (recommended first run)
java -jar target/fanout-engine.jar --testMode

# ğŸš€ Production mode (stream records from file)
java -jar target/fanout-engine.jar

# ğŸ’¾ With custom heap size (for large files)
java -Xmx2g -jar target/fanout-engine.jar

# ğŸ”Œ Run via Maven plugin (no JAR needed)
mvn exec:java

# ğŸ› Debug mode (port 5005)
java -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005 \
     -jar target/fanout-engine.jar
```

### Configuration

Before running, customize settings in `src/main/resources/application.yaml`:

```yaml
# Change input file and format
input:
  filePath: "sample-data/input.json"
  format: "jsonl"  # Options: json, jsonl, csv, fixedwidth

# Adjust queue size (larger = more memory, less blocking)
queue:
  capacity: 1000

# Tune sink throughput limits
sinks:
  rest:
    rateLimit: 50       # Requests per second
  grpc:
    rateLimit: 200
  mq:
    rateLimit: 500
  db:
    rateLimit: 1000
```

### Verify Installation

```bash
# âœ… Check Java 21+
java -version
# Expected: openjdk version "21" or higher

# âœ… Check Maven 3.8+
mvn -version
# Expected: Apache Maven 3.8.0 or higher

# âœ… Verify project structure
ls -la src/main/java/com/fanout/
# Should show directories: config, core, dlq, ingestion, sink, transform, util
```

### Troubleshooting

| Issue | Solution |
|-------|----------|
| `mvn: command not found` | Install Maven or add to PATH |
| `java version 11/17 (not 21)` | Upgrade Java to version 21: `java -version` |
| `input.json not found` | File exists at `sample-data/input.json` |
| Tests fail with errors | Run `mvn clean compile` first, check Java version |
| Thread timeout errors | Increase JVM timeout: `MAVEN_OPTS="-Dorg.awaitility.timeout=10s"` |
| Low throughput output | Edit `application.yaml` to increase sink rate limits |

---

## ğŸ“Š Metrics Output

Every 5 seconds, the engine prints real-time metrics:

```
ğŸ“Š === METRICS REPORT ===
   Processed: 5000
   Throughput: 1000 records/sec
   Success: {REST=1250, GRPC=1250, MQ=1250, DB=1250}
   Failed: {REST=12, GRPC=8, MQ=5, DB=3}
   DLQ Records: 28
========================
```

**Metrics Explained:**
- **Processed**: Total records read from input file
- **Throughput**: Records processed per second
- **Success**: Successful deliveries per sink
- **Failed**: Failed deliveries per sink (before DLQ)
- **DLQ Records**: Failed records persisted to `dlq/failed-records.jsonl`

---

## ğŸ”„ Retry & DLQ Flow

```
Record â†’ Sink.send()
    â”œâ”€ Attempt 1: Fails
    â”œâ”€ Attempt 2: Fails  
    â”œâ”€ Attempt 3: Fails
    â””â”€ â†’ DeadLetterQueue (persisted to file)

DLQ File Format (JSONL):
{"record": {...}, "sink": "REST", "attempts": 3, "error": "Network timeout", "timestamp": "2024-02-17T..."}
```

**Recovery**: Failed records can be replayed by re-processing the DLQ file with a corrected configuration.

---

## ğŸ§ª Testing

### Test Suite

```bash
# Run all tests
mvn test

# Run all tests with coverage
mvn test jacoco:report

# Run specific test class
mvn test -Dtest=DLQTest

# Run specific test method
mvn test -Dtest=DLQTest#testRecordFailure
```

### Available Tests

- âœ… **SinkBehaviorTest** (5 tests) - Mockito-based sink behavior verification
- âœ… **DLQTest** (6 tests) - Dead Letter Queue file persistence
- âœ… **TransformerTest** (9 tests) - Data format transformation validation
- âœ… **RetryTest** (1 test) - Retry logic verification
- âœ… **IntegrationTest** (1 test) - End-to-end pipeline
- âœ… **RetryIntegrationTest** (1 test) - Failure resilience

**Total: 23 tests** âœ… All passing

### Test Technologies
- **JUnit 5**: Testing framework
- **Mockito**: Mocking sinks and dependencies
- **Temporary directories**: For DLQ file testing (auto-cleanup)

---

## ğŸ“ Design Patterns

| Pattern | Component | Benefit |
|---------|-----------|---------|
| **Strategy** | Transformers (JSON/XML/Proto/Avro) | Swap format logic at runtime |
| **Factory** | `createSinks()` method | Encapsulate sink creation, adds extensibility |
| **Template Method** | `BaseSink` rate limiting | Code reuse, DRY principle |
| **Observer** | Metrics reporter | Decouple monitoring from core logic |
| **Producer-Consumer** | BlockingQueue | Backpressure & flow control |
| **Singleton** | ConfigLoader | Single source of configuration truth |

---

## ğŸ”Œ Extensibility Example: Adding Elasticsearch

To add a new sink (e.g., Elasticsearch) without modifying core logic:

```java
// Step 1: Create Sink Implementation
public class ElasticsearchSink extends BaseSink {
    public ElasticsearchSink(int rate) { 
        super(rate); 
    }
    
    @Override
    public CompletableFuture<Boolean> send(String data) { 
        // Implementation here
        return CompletableFuture.completedFuture(true);
    }
    
    @Override
    public String name() { 
        return "ELASTICSEARCH"; 
    }
}

// Step 2: Create Transformer (if needed)
public class ElasticsearchTransformer implements Transformer {
    @Override
    public String transform(String input) {
        // Convert JSON to Elasticsearch bulk format
        return input;
    }
}

// Step 3: Update configuration
# application.yaml
sinks:
  elasticsearch:
    rateLimit: 800
    endpoint: "http://localhost:9200"

// Step 4: Register in FanOutOrchestrator (1-line change)
sinkList.add(new ElasticsearchSink(
    config.getInt("sinks.elasticsearch.rateLimit", 800)
));
```

**Result**: New sink integrated without modifying core `FanOutOrchestrator` logic! âœ¨

---

## ğŸ“‚ Project Structure

```
High-Throughput-Fan-Out-Engine/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/fanout/
â”‚   â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ConfigLoader.java          # Load application.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FanOutOrchestrator.java    # Main orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ dlq/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DeadLetterQueue.java       # DLQ persistence
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FileProducer.java          # Multi-format reader
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Metrics.java               # Observability
â”‚   â”‚   â”‚   â”œâ”€â”€ sink/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sink.java (interface)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ BaseSink.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RestSink.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GrpcSink.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageQueueSink.java
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ WideColumnDbSink.java
â”‚   â”‚   â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Transformer.java (interface)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ JsonTransformer.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ XmlTransformer.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProtoTransformer.java
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ AvroTransformer.java
â”‚   â”‚   â”‚   â”œâ”€â”€ util/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Metrics.java
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SimpleRateLimiter.java
â”‚   â”‚   â”‚   â””â”€â”€ Main.java                      # Entry point
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ application.yaml                # Configuration file
â”‚   â”‚
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ java/com/fanout/
â”‚           â”œâ”€â”€ SinkBehaviorTest.java          # Mockito tests
â”‚           â”œâ”€â”€ DLQTest.java                   # DLQ persistence tests
â”‚           â”œâ”€â”€ TransformerTest.java           # Transformation tests
â”‚           â”œâ”€â”€ RetryTest.java                 # Retry logic tests
â”‚           â”œâ”€â”€ IntegrationTest.java           # E2E tests
â”‚           â””â”€â”€ RetryIntegrationTest.java      # Resilience tests
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md                        # Detailed design docs
â”‚   â””â”€â”€ DESIGN_DIAGRAMS.md                     # Visual diagrams
â”‚
â”œâ”€â”€ dlq/                                       # Created at runtime
â”‚   â””â”€â”€ failed-records.jsonl                   # Persisted failures
â”‚
â”œâ”€â”€ sample-data/
â”‚   â””â”€â”€ input.json                             # Sample input
â”‚
â”œâ”€â”€ pom.xml                                    # Maven configuration
â”œâ”€â”€ README.md                                  # This file
â””â”€â”€ .gitignore
```

---

## ğŸ’¾ Memory Management

### Streaming Architecture
- **File Reading**: Line-by-line (no full load)
- **Queue**: Fixed capacity (default 1000)
- **Transformers**: String objects only
- **Metrics**: Atomic variables (minimal footprint)

### Memory Usage Estimate
```
Memory = Queue Capacity Ã— Avg Record Size + Overhead
       = 1000 Ã— 10KB + 5MB
       â‰ˆ 15MB (typical)
```

### Running with Limited Heap
```bash
java -Xmx512m -jar target/fanout-engine.jar
```

Even with **100GB files**, memory usage stays under **512MB**! ğŸ¯

---

## ğŸš„ Performance Characteristics

### Scalability
- **Linear with CPU cores** (Virtual Threads)
- N records Ã— 4 sinks = 4N concurrent tasks
- Work-stealing scheduler distributes load

### Throughput Bottleneck
```
Max Throughput = min(disk I/O, slowest_sink_rate)
               â‰ˆ 2000-3000 records/sec (typical)

With optimization:
- Increase sink rates: Edit application.yaml
- Increase queue capacity: Prevent producer blocking
- Tune heap size: More memory â†’ larger buffers
```

---

## ğŸ›¡ï¸ Resilience & Zero Data Loss

### Retry Mechanism
- Max 3 attempts per sink
- Exponential backoff between retries
- Detailed error logging

### Dead Letter Queue (DLQ)
- Persists ALL failed records to file
- Includes full context (record + sink + error + timestamp)
- Async write (doesn't block sink)
- Can be replayed manually or via automation

### Failure Scenarios Handled
1. âœ… Network timeouts â†’ Retry â†’ DLQ
2. âœ… Invalid format â†’ Log error â†’ DLQ
3. âœ… Sink unavailable â†’ Retry â†’ DLQ
4. âœ… Application crash â†’ DLQ file survives (recovery)

---

## ğŸ“– Design Documentation

For detailed architecture and design patterns, see:
- [ARCHITECTURE.md](docs/ARCHITECTURE.md) - System design, patterns, scalability
- [DESIGN_DIAGRAMS.md](docs/DESIGN_DIAGRAMS.md) - Visual diagrams and flows

---

## ğŸ” Key Components

### 1. ConfigLoader
Loads `application.yaml` and provides typed access:
```java
ConfigLoader config = ConfigLoader.getInstance();
int queueCapacity = config.getInt("queue.capacity", 1000);
String filePath = config.getString("input.filePath", "...");
```

### 2. FileProducer
Multi-format file reader with streaming support:
```java
new FileProducer(queue, "input.json", "jsonl")
```

### 3. FanOutOrchestrator
Main orchestrator coordinating the entire pipeline:
```java
orchestrator.start(true);           // Production mode
orchestrator.startTestMode(100);    // Test mode
```

### 4. DeadLetterQueue
Persistent failure tracking:
```java
dlq.recordFailure(record, "REST", 3, "Network error");
dlq.getFailedRecords();
dlq.getFailedCount();
```

### 5. Sink Implementations
Each sink extends `BaseSink`:
- RestSink, GrpcSink, MessageQueueSink, WideColumnDbSink
- All support rate limiting via semaphore
- Return `CompletableFuture<Boolean>`

### 6. Transformers
Strategy pattern for data transformation:
- JsonTransformer, XmlTransformer, ProtoTransformer, AvroTransformer

---

## ğŸ“Š Evaluation Against Requirements

| Requirement | Status | Evidence |
|--|--|--|
| Ingestion Layer | âœ… Complete | FileProducer with multiple formats |
| Transformation Layer | âœ… Complete | 4 transformers using Strategy pattern |
| Distribution Layer | âœ… Complete | 4 sink implementations |
| Throttling | âœ… Complete | Semaphore-based rate limiting |
| Backpressure | âœ… Complete | BlockingQueue with configurable capacity |
| Error Handling | âœ… Complete | Retry logic + DLQ |
| Concurrency (Virtual Threads) | âœ… Complete | `newVirtualThreadPerTaskExecutor()` |
| Config-Driven | âœ… Complete | `application.yaml` + ConfigLoader |
| Observability | âœ… Complete | Metrics every 5 seconds |
| Zero Data Loss | âœ… Complete | DeadLetterQueue |
| Unit Tests | âœ… Complete | Mockito-based tests |
| Integration Tests | âœ… Complete | End-to-end pipeline tests |
| Design Patterns | âœ… Complete | Strategy, Factory, Template Method, Observer |
| Design Docs | âœ… Complete | ARCHITECTURE.md + DESIGN_DIAGRAMS.md |
| Extensibility | âœ… Complete | Factory pattern + config-driven |
| Memory Efficiency | âœ… Complete | Streaming + fixed buffers |

---

## ğŸ¯ Quick Reference

### Common Commands

```bash
# âš¡ Quick setup
mvn clean install && java -jar target/fanout-engine.jar --testMode

# ğŸ“Š Run tests with output
mvn clean test -X -e

# ğŸ”§ Build without tests (fast)
mvn clean package -DskipTests -q

# ğŸ¯ Run production mode
java -jar target/fanout-engine.jar

# ğŸ§ª Run specific test
mvn test -Dtest=IntegrationTest -e

# ğŸ“ˆ Check metrics
# Look for "ğŸ“Š === METRICS REPORT ===" in output

# ğŸ’¾ View failed records
cat dlq/failed-records.jsonl | head -10

# ğŸ—‘ï¸ Clean build artifacts
mvn clean

# ğŸ” Debug mode
export MAVEN_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005"
mvn exec:java
```

### Configuration Quick Tips

| Setting | Purpose | Range | Default |
|---------|---------|-------|---------|
| `queue.capacity` | Memory buffer size | 100-10000 | 1000 |
| `input.format` | File format to read | json/jsonl/csv/fixedwidth | jsonl |
| `sinks.*.rateLimit` | Max requests/sec | 1-10000 | See yaml |
| `dlq.maxRetries` | Max retry attempts | 1-10 | 3 |
| `metrics.intervalSeconds` | Report frequency | 1-60 | 5 |

### Performance Tuning

**For Large Files:**
```bash
java -Xmx4g -XX:+UseG1GC -jar target/fanout-engine.jar
```

**For High Throughput:**
```yaml
# In application.yaml
queue:
  capacity: 5000
sinks:
  db:
    rateLimit: 5000  # Increase slowest sink
```

**For Low-Latency:**
```yaml
queue:
  capacity: 100  # Smaller buffer
sinks:
  rest:
    rateLimit: 1000  # Higher throughput
```

---

## ğŸ“š Documentation Map

| Document | Purpose |
|---|---|
| [README.md](README.md) | Overview & quick start (you are here) |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Deep dive into design, patterns, scalability |
| [DESIGN_DIAGRAMS.md](docs/DESIGN_DIAGRAMS.md) | Visual architecture, data flows, diagrams |
| [pom.xml](pom.xml) | Maven configuration, dependencies |
| [application.yaml](src/main/resources/application.yaml) | All configuration options |

---

## ğŸ› Debug Tips

### Enable Verbose Logging
```bash
mvn clean install -X
java -jar target/fanout-engine.jar 2>&1 | tee app.log
```

### Monitor JVM
```bash
jps -l  # List Java processes
jstat -gc <pid> 500  # Monitor GC every 500ms
jmap -heap <pid>  # Heap snapshot
```

### Check DLQ for Failures
```bash
# Count failed records
wc -l dlq/failed-records.jsonl

# View recent failures
tail -5 dlq/failed-records.jsonl

# Extract specific sink failures
grep '"sink":"REST"' dlq/failed-records.jsonl | wc -l
```

### Profile Application
```bash
# Using JProfiler or YourKit (if installed)
java -agentpath:/path/to/profiler -jar target/fanout-engine.jar

# Using JFR (Java Flight Recorder)
java -XX:+UnlockCommercialFeatures -XX:+FlightRecorder \
     -XX:StartFlightRecording=duration=30s,filename=recording.jfr \
     -jar target/fanout-engine.jar
```

---

## ğŸ“ Learning Path

1. **Beginner**: Read overview section above
2. **Intermediate**: Run test mode, examine test files
3. **Advanced**: Read [ARCHITECTURE.md](docs/ARCHITECTURE.md) and [DESIGN_DIAGRAMS.md](docs/DESIGN_DIAGRAMS.md)
4. **Expert**: Implement new sink following extensibility example

---

## â“ FAQ

**Q: How do I process my own data file?**
```
A: Place your file in ./sample-data/ and update application.yaml:
   input:
     filePath: "sample-data/my-file.csv"
     format: "csv"
```

**Q: What if records keep failing to one sink?**
```
A: Check the sink's rate limit and error reason in dlq/failed-records.jsonl:
   1. Review the error reason
   2. Fix the issue (e.g., adjust config)
   3. Retry the records
```

**Q: How do I increase throughput?**
```
A: 1. Increase queue.capacity (uses more memory)
   2. Increase slowest sink rate limit
   3. Use larger JVM heap: java -Xmx4g
   4. Check disk I/O speed
```

**Q: Can I run multiple instances in parallel?**
```
A: Yes! Each instance reads from the same file but maintains
   separate queues and DLQs. Coordinate via external database.
```

**Q: How do I replay failed records from DLQ?**
```
A: 1. Fix the underlying issue (sink config, network, etc)
   2. Manually parse dlq/failed-records.jsonl
   3. Re-submit through producer or via batch script
```
